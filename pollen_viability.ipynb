{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubstenc/Pollen_viability/blob/main/pollen_viability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå∏ Pollen Viability Deep Learning Pipeline (YOLOv8)\n",
        "\n",
        "**Project:** Automated counting of viable (stained) vs. non-viable (pale) pollen grains.\n",
        "**Author:** Jakub ≈†tenc\n",
        "**Model:** YOLOv8 (Medium/Large)\n",
        "\n",
        "This pipeline performs three main functions:\n",
        "1.  **Data Management:** Safely merges new annotations (from Roboflow) and splits them into Train/Validation sets.\n",
        "2.  **Training:** Retrains the model using specific biological augmentations (rotation, color invariance).\n",
        "3.  **Inference:** Detects pollen in new microscope images using dynamic resolution switching.\n",
        "\n",
        "---\n",
        "### üõ†Ô∏è Step 1: Environment Setup\n",
        "Run this cell to mount Google Drive and install the necessary computer vision libraries.\n",
        "* **Mounts:** `/content/drive`\n",
        "* **Installs:** `ultralytics` (YOLOv8)"
      ],
      "metadata": {
        "id": "EvRYMRKHrZ0j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1CJ6fT2aaDn"
      },
      "source": [
        "# 1. Install yolo from Ultralytics, import libraries, mount google drive and locate the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3twYRgUDIK8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcabe9e-1d06-462a-9cef-199c1e990d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Setup complete. Ready to train!\n"
          ]
        }
      ],
      "source": [
        "# --- SETUP CELL ---\n",
        "# Run this once at the start of every session\n",
        "\n",
        "# 1. Mount Google Drive (to access your data)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Install YOLO (The computer forgets this when you close the tab)\n",
        "!pip install ultralytics -q\n",
        "\n",
        "# 3. Import libraries\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load a model\n",
        "# 'yolov8n.pt' is the \"Nano\" model (smallest & fastest).\n",
        "# Good for testing if the pipeline works.\n",
        "# Later we can use 'yolov8m.pt' (Medium) or 'yolov8x.pt' (Extra Large) for better accuracy.\n",
        "model = YOLO('yolov8l.pt')\n",
        "\n",
        "print(\"Setup complete. Ready to train!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Updating the training dataset"
      ],
      "metadata": {
        "id": "kh8GC6LjQA7e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEVbde7SQLSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding the empty data\n"
      ],
      "metadata": {
        "id": "jxwGXORrQLl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# 1. INPUT: Folder where you put your small smudge crops\n",
        "input_smudges_dir = '/content/drive/MyDrive/Pollen_viability/smudges_raw'\n",
        "\n",
        "# 2. STAGING: Where we generate the canvas images first\n",
        "staging_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train_negatives'\n",
        "os.makedirs(os.path.join(staging_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(staging_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "# 3. DESTINATION: Your actual training dataset\n",
        "train_img_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/images'\n",
        "train_lbl_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels'\n",
        "\n",
        "# Settings\n",
        "CANVAS_SIZE = 640\n",
        "BACKGROUND_COLOR = (245, 245, 245) # Light Gray\n",
        "\n",
        "print(\"üß™ Starting Smudge Synthesis & Integration...\")\n",
        "\n",
        "if not os.path.exists(input_smudges_dir) or not os.listdir(input_smudges_dir):\n",
        "    print(f\"‚ùå Error: Folder '{input_smudges_dir}' is empty or missing.\")\n",
        "else:\n",
        "    files = [f for f in os.listdir(input_smudges_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    print(f\"   Found {len(files)} smudge source files.\")\n",
        "\n",
        "    generated_count = 0\n",
        "\n",
        "    # --- PHASE 1: GENERATE IMAGES ---\n",
        "    for i, fname in enumerate(tqdm(files, desc=\"Synthesizing\")):\n",
        "        # Unique name based on original filename to prevent collisions\n",
        "        base_name = os.path.splitext(fname)[0]\n",
        "        new_name = f\"neg_syn_{base_name}.jpg\"\n",
        "        label_name = f\"neg_syn_{base_name}.txt\"\n",
        "\n",
        "        output_img_path = os.path.join(staging_dir, 'images', new_name)\n",
        "        output_lbl_path = os.path.join(staging_dir, 'labels', label_name)\n",
        "\n",
        "        # Load Smudge\n",
        "        smudge = cv2.imread(os.path.join(input_smudges_dir, fname))\n",
        "        if smudge is None: continue\n",
        "        h, w = smudge.shape[:2]\n",
        "\n",
        "        # Create Canvas\n",
        "        canvas = np.full((CANVAS_SIZE, CANVAS_SIZE, 3), BACKGROUND_COLOR, dtype=np.uint8)\n",
        "\n",
        "        # Resize if needed\n",
        "        if w > CANVAS_SIZE or h > CANVAS_SIZE:\n",
        "            scale = min(CANVAS_SIZE/w, CANVAS_SIZE/h)\n",
        "            smudge = cv2.resize(smudge, (0,0), fx=scale, fy=scale)\n",
        "            h, w = smudge.shape[:2]\n",
        "\n",
        "        # Center Paste\n",
        "        x_off = (CANVAS_SIZE - w) // 2\n",
        "        y_off = (CANVAS_SIZE - h) // 2\n",
        "        canvas[y_off:y_off+h, x_off:x_off+w] = smudge\n",
        "\n",
        "        # Save to Staging\n",
        "        cv2.imwrite(output_img_path, canvas)\n",
        "        with open(output_lbl_path, 'w') as f:\n",
        "            pass # Empty label\n",
        "\n",
        "        generated_count += 1\n",
        "\n",
        "    # --- PHASE 2: INTEGRATE TO TRAIN ---\n",
        "    print(f\"\\nüì¶ Phase 2: Integrating {generated_count} samples into Training Set...\")\n",
        "\n",
        "    added_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    generated_files = os.listdir(os.path.join(staging_dir, 'images'))\n",
        "\n",
        "    for img_file in generated_files:\n",
        "        # Source Paths (Staging)\n",
        "        src_img = os.path.join(staging_dir, 'images', img_file)\n",
        "        src_lbl = os.path.join(staging_dir, 'labels', img_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        # Dest Paths (Training)\n",
        "        dst_img = os.path.join(train_img_dir, img_file)\n",
        "        dst_lbl = os.path.join(train_lbl_dir, img_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        # Check if exists\n",
        "        if os.path.exists(dst_img):\n",
        "            skipped_count += 1\n",
        "        else:\n",
        "            # Move it!\n",
        "            shutil.move(src_img, dst_img)\n",
        "            shutil.move(src_lbl, dst_lbl)\n",
        "            added_count += 1\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"‚úÖ Integration Complete!\")\n",
        "    print(f\"   üÜï Added:   {added_count} new images\")\n",
        "    print(f\"   ‚è≠Ô∏è Skipped: {skipped_count} duplicates (already in training)\")\n",
        "    print(f\"   üìÇ Training set updated: {train_img_dir}\")"
      ],
      "metadata": {
        "id": "c_8rGdGrQBiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßπ Step 2: Dataset Health Check & Cleaning\n",
        "**\"Garbage In, Garbage Out.\"** These scripts ensure your dataset is clean before training.\n",
        "\n",
        "1.  **Quarantine Unlabeled Images:** Moves images without corresponding `.txt` files to a quarantine folder (prevents them from acting as \"negative samples\").\n",
        "2.  **Purge Corrupted Labels:** Deletes empty or corrupted label files (orphans) from both Training and Validation sets.\n",
        "3.  **Fix Drive Errors:** Scans for and removes `.gdoc` files that Google Drive sometimes creates by mistake.\n",
        "\n",
        "*Run these cells sequentially to sanitize your data folders.*"
      ],
      "metadata": {
        "id": "3LAQbuCn1EXn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44IQaQsj6L9W"
      },
      "source": [
        "### Cleaning the training dataset from images without labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO5b2N8V6KFq",
        "outputId": "a4cd975f-179f-4741-8884-0d59521d50ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning for unlabeled images...\n",
            "\n",
            "--- Cleanup Complete ---\n",
            "All images have labels. You are good to go!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Your training folders\n",
        "train_img_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/images'\n",
        "train_lbl_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels'\n",
        "\n",
        "# Where to put the \"problem\" images\n",
        "quarantine_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/quarantine_unlabeled'\n",
        "os.makedirs(quarantine_dir, exist_ok=True)\n",
        "\n",
        "print(\"Scanning for unlabeled images...\")\n",
        "\n",
        "moved_count = 0\n",
        "image_files = [f for f in os.listdir(train_img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "for img_file in image_files:\n",
        "    # Construct the expected label filename\n",
        "    # R Analogy: paste0(tools::file_path_sans_ext(img_file), \".txt\")\n",
        "    label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
        "    label_path = os.path.join(train_lbl_dir, label_file)\n",
        "\n",
        "    # Check if the label file exists\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"‚ö†Ô∏è No label found for: {img_file}. Moving to quarantine.\")\n",
        "\n",
        "        # Move the image out of the training set\n",
        "        src_path = os.path.join(train_img_dir, img_file)\n",
        "        dst_path = os.path.join(quarantine_dir, img_file)\n",
        "        shutil.move(src_path, dst_path)\n",
        "        moved_count += 1\n",
        "\n",
        "print(f\"\\n--- Cleanup Complete ---\")\n",
        "if moved_count > 0:\n",
        "    print(f\"‚úÖ Moved {moved_count} unlabeled images to: {quarantine_dir}\")\n",
        "    print(\"Your training folder is now safe!\")\n",
        "else:\n",
        "    print(\"All images have labels. You are good to go!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FkebbMh-2iY"
      },
      "source": [
        "### Checking for corrupted labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Mky-K7-xJK",
        "outputId": "a5b1dee9-3186-457a-eda6-cd0ceb77c750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Starting Google Doc Purge...\n",
            "\n",
            "Scanning: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels\n",
            "\n",
            "Scanning: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/labels\n",
            "\n",
            "--- PURGE COMPLETE ---\n",
            "Deleted 0 corrupted files.\n",
            "No .gdoc files found. Your labels might be clean (or the corruption is different).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Check both Train and Val folders\n",
        "folders_to_check = [\n",
        "    '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels',\n",
        "    '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/labels'\n",
        "]\n",
        "\n",
        "print(\"üßπ Starting Google Doc Purge...\")\n",
        "\n",
        "total_deleted = 0\n",
        "affected_images = []\n",
        "\n",
        "for folder in folders_to_check:\n",
        "    print(f\"\\nScanning: {folder}\")\n",
        "\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Skipping {folder} (does not exist)\")\n",
        "        continue\n",
        "\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    for f in files:\n",
        "        file_path = os.path.join(folder, f)\n",
        "\n",
        "        # Check 1: Explicit extension\n",
        "        if f.endswith('.gdoc'):\n",
        "            print(f\"   ‚ùå Found .gdoc file: {f} -> DELETING.\")\n",
        "            os.remove(file_path)\n",
        "            total_deleted += 1\n",
        "            # Record the image name that needs a fix\n",
        "            affected_images.append(f.replace('.gdoc', '.jpg')) # Assuming jpg, check your ext\n",
        "\n",
        "        # Check 2: Implicit conversion (File has no extension but is a gdoc link)\n",
        "        # Sometimes Drive removes the extension entirely!\n",
        "        elif os.path.isfile(file_path) and not f.endswith('.txt'):\n",
        "            # Peek inside to see if it looks like JSON/HTML\n",
        "            try:\n",
        "                with open(file_path, 'r', errors='ignore') as check:\n",
        "                    header = check.read(100)\n",
        "                    if \"google\" in header.lower() or \"{\" in header:\n",
        "                        print(f\"   ‚ùå Found hidden GDoc link: {f} -> DELETING.\")\n",
        "                        os.remove(file_path)\n",
        "                        total_deleted += 1\n",
        "                        affected_images.append(f + \".jpg\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "print(f\"\\n--- PURGE COMPLETE ---\")\n",
        "print(f\"Deleted {total_deleted} corrupted files.\")\n",
        "\n",
        "if total_deleted > 0:\n",
        "    print(\"\\n‚ö†Ô∏è ACTION REQUIRED:\")\n",
        "    print(\"The following labels were corrupted and deleted. You must RE-UPLOAD them as valid .txt files:\")\n",
        "    for img in affected_images[:10]: # Print first 10\n",
        "        print(f\" - Label for: {img}\")\n",
        "    if len(affected_images) > 10:\n",
        "        print(f\" ... and {len(affected_images)-10} others.\")\n",
        "\n",
        "    print(\"\\nüí° TIP: When re-uploading, zip them first ('labels.zip') and unzip in Colab!\")\n",
        "else:\n",
        "    print(\"No .gdoc files found. Your labels might be clean (or the corruption is different).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZA-i0nd9gak"
      },
      "source": [
        "### Checking if every training image has a label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbZkD9tm7WKp",
        "outputId": "049a93e5-c3ea-4690-ccc8-7f0b31586dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting labels in: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels\n",
            "Found 252 .txt files.\n",
            "\n",
            "--- FORMAT CHECK ---\n",
            "\n",
            "--- MATCHING CHECK ---\n",
            "\n",
            "‚úÖ GREAT NEWS: Your labels look perfect!\n",
            "üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting labels in: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels\n",
            "Found 252 .txt files.\n",
            "\n",
            "--- CHECKING FOR ORPHANS ---\n",
            "\n",
            "--- SUMMARY ---\n",
            "‚úÖ All labels have matching images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "label_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels'\n",
        "image_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/images'\n",
        "\n",
        "print(f\"üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting labels in: {label_dir}\")\n",
        "\n",
        "txt_files = glob.glob(os.path.join(label_dir, \"*.txt\"))\n",
        "print(f\"Found {len(txt_files)} .txt files.\")\n",
        "\n",
        "errors_found = 0\n",
        "\n",
        "# 1. Check a sample of files for FORMAT errors\n",
        "print(\"\\n--- FORMAT CHECK ---\")\n",
        "for i, txt_file in enumerate(txt_files):\n",
        "    if i > 10: break # Only check first 10 to save time\n",
        "\n",
        "    with open(txt_file, 'r') as f:\n",
        "        try:\n",
        "            content = f.read().strip()\n",
        "            filename = os.path.basename(txt_file)\n",
        "\n",
        "            # Error A: Empty File\n",
        "            if not content:\n",
        "                print(f\"‚ùå EMPTY FILE: {filename}\")\n",
        "                errors_found += 1\n",
        "                continue\n",
        "\n",
        "            lines = content.split('\\n')\n",
        "            first_line = lines[0].strip()\n",
        "\n",
        "            # Error B: Wrong Separator (Commas)\n",
        "            if \",\" in first_line:\n",
        "                print(f\"‚ùå COMMA DETECTED (Needs spaces): {filename} -> '{first_line}'\")\n",
        "                errors_found += 1\n",
        "\n",
        "            # Error C: Coordinates not Normalized (Values > 1)\n",
        "            parts = first_line.split()\n",
        "            if len(parts) >= 5:\n",
        "                # check x, y, w, h\n",
        "                coords = [float(p) for p in parts[1:5]]\n",
        "                if any(c > 1.0 for c in coords):\n",
        "                    print(f\"‚ùå COORDINATES > 1 (Must be 0-1): {filename} -> {coords}\")\n",
        "                    errors_found += 1\n",
        "            else:\n",
        "                print(f\"‚ùå MALFORMED LINE (Not enough columns): {filename} -> '{first_line}'\")\n",
        "                errors_found += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå CRITICAL ERROR reading {filename}: {e}\")\n",
        "            errors_found += 1\n",
        "\n",
        "# 2. Check for FILENAME MISMATCHES (Case Sensitivity)\n",
        "print(\"\\n--- MATCHING CHECK ---\")\n",
        "images = os.listdir(image_dir)\n",
        "# Clean extensions to compare base names\n",
        "img_bases = {os.path.splitext(f)[0]: f for f in images}\n",
        "\n",
        "mismatches = 0\n",
        "for txt_file in txt_files:\n",
        "    base_name = os.path.splitext(os.path.basename(txt_file))[0]\n",
        "\n",
        "    # Check if exact match exists\n",
        "    if base_name not in img_bases:\n",
        "        print(f\"‚ö†Ô∏è ORPHAN LABEL: {base_name}.txt exists, but no matching image found!\")\n",
        "        mismatches += 1\n",
        "\n",
        "if errors_found == 0 and mismatches == 0:\n",
        "    print(\"\\n‚úÖ GREAT NEWS: Your labels look perfect!\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è FOUND ISSUES: {errors_found} format errors, {mismatches} mismatch errors.\")\n",
        "\n",
        "\n",
        "###### DELETING ORPHANS ######\n",
        "\n",
        "# SET THIS TO TRUE TO ACTUALLY DELETE FILES\n",
        "tDELETE_ORPHANS = True\n",
        "\n",
        "print(f\"üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting labels in: {label_dir}\")\n",
        "\n",
        "txt_files = glob.glob(os.path.join(label_dir, \"*.txt\"))\n",
        "print(f\"Found {len(txt_files)} .txt files.\")\n",
        "\n",
        "# --- MATCHING & PURGE CHECK ---\n",
        "print(\"\\n--- CHECKING FOR ORPHANS ---\")\n",
        "images = os.listdir(image_dir)\n",
        "# Create a set of valid image names (without extension) for fast lookup\n",
        "img_bases = {os.path.splitext(f)[0] for f in images if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
        "\n",
        "mismatches = 0\n",
        "deleted_count = 0\n",
        "\n",
        "for txt_file in txt_files:\n",
        "    # Get the filename without extension (e.g., \"flower_01\")\n",
        "    base_name = os.path.splitext(os.path.basename(txt_file))[0]\n",
        "\n",
        "    # Check if this base name exists in our image list\n",
        "    if base_name not in img_bases:\n",
        "        if DELETE_ORPHANS:\n",
        "            print(f\"üóëÔ∏è DELETING ORPHAN: {base_name}.txt (No matching image)\")\n",
        "            os.remove(txt_file)\n",
        "            deleted_count += 1\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è FOUND ORPHAN: {base_name}.txt (Set DELETE_ORPHANS=True to remove)\")\n",
        "\n",
        "        mismatches += 1\n",
        "\n",
        "print(f\"\\n--- SUMMARY ---\")\n",
        "if mismatches == 0:\n",
        "    print(\"‚úÖ All labels have matching images.\")\n",
        "else:\n",
        "    if DELETE_ORPHANS:\n",
        "        print(f\"üßπ Purged {deleted_count} orphan label files.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Found {mismatches} orphan labels. No files were deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs6LcvA19q6m"
      },
      "source": [
        "### Checking if every validation  image has a label + deleting orphans\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# CHANGED: Pointing to 'val' folders now\n",
        "label_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/labels'\n",
        "image_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/images'\n",
        "\n",
        "# SET THIS TO TRUE TO ACTUALLY DELETE FILES\n",
        "DELETE_ORPHANS = True\n",
        "\n",
        "print(f\"üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting Validation labels in: {label_dir}\")\n",
        "\n",
        "txt_files = glob.glob(os.path.join(label_dir, \"*.txt\"))\n",
        "print(f\"Found {len(txt_files)} .txt files.\")\n",
        "\n",
        "# --- MATCHING & PURGE CHECK ---\n",
        "print(\"\\n--- CHECKING FOR ORPHANS ---\")\n",
        "images = os.listdir(image_dir)\n",
        "# Create a set of valid image names (without extension) for fast lookup\n",
        "img_bases = {os.path.splitext(f)[0] for f in images if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
        "\n",
        "mismatches = 0\n",
        "deleted_count = 0\n",
        "\n",
        "for txt_file in txt_files:\n",
        "    # Get the filename without extension (e.g., \"flower_01\")\n",
        "    base_name = os.path.splitext(os.path.basename(txt_file))[0]\n",
        "\n",
        "    # Check if this base name exists in our image list\n",
        "    if base_name not in img_bases:\n",
        "        if DELETE_ORPHANS:\n",
        "            print(f\"üóëÔ∏è DELETING ORPHAN: {base_name}.txt (No matching image)\")\n",
        "            os.remove(txt_file)\n",
        "            deleted_count += 1\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è FOUND ORPHAN: {base_name}.txt (Set DELETE_ORPHANS=True to remove)\")\n",
        "\n",
        "        mismatches += 1\n",
        "\n",
        "print(f\"\\n--- SUMMARY ---\")\n",
        "if mismatches == 0:\n",
        "    print(\"‚úÖ All validation labels have matching images.\")\n",
        "else:\n",
        "    if DELETE_ORPHANS:\n",
        "        print(f\"üßπ Purged {deleted_count} orphan label files from Validation.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Found {mismatches} orphan labels. No files were deleted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QrImKgkqjFA",
        "outputId": "b8feb487-d7fe-4905-b604-e73e749aa53d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üïµÔ∏è‚Äç‚ôÄÔ∏è Inspecting Validation labels in: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/labels\n",
            "Found 54 .txt files.\n",
            "\n",
            "--- CHECKING FOR ORPHANS ---\n",
            "\n",
            "--- SUMMARY ---\n",
            "‚úÖ All validation labels have matching images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOH1igH5YO3N"
      },
      "source": [
        "### üëÅÔ∏è Step 4: Ground Truth Visualization\n",
        "**Critical Sanity Check:** Before training, we must verify that the \"Teacher\" (the labels) is correct.\n",
        "This script draws the bounding boxes from your `.txt` files onto the images.\n",
        "\n",
        "* **Check Output:** Go to `datasets/pollen_v1/check_train_labels_visual`.\n",
        "* **Verify:**\n",
        "    * **Green Box** = Viable (Class 0) -> Should encompass dark/stained grains.\n",
        "    * **Red Box** = Non-Viable (Class 1) -> Should encompass pale/transparent grains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm5JfvSUFCLW",
        "outputId": "029ac5b9-ac45-4d57-d591-a91f53ddd63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Visual Inspection for ALL data...\n",
            "\n",
            "--- Processing TRAIN set ---\n",
            "Saving images to: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/check_train_labels_visual\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:07<00:00, 31.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing VAL set ---\n",
            "Saving images to: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/check_val_labels_visual\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [00:01<00:00, 29.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done! Please check these folders in your Drive:\n",
            "1. /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/check_train_labels_visual\n",
            "2. /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/check_val_labels_visual\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Base path to your dataset\n",
        "base_dataset_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1'\n",
        "\n",
        "# We will check both splits\n",
        "splits_to_check = ['train', 'val']\n",
        "\n",
        "# Visualization Settings\n",
        "COLOR_MAP = {\n",
        "    0: (0, 255, 0),    # Class 0 (Viable) = Green\n",
        "    1: (0, 0, 255)     # Class 1 (Non-Viable) = Red\n",
        "}\n",
        "BOX_THICKNESS = 2\n",
        "\n",
        "print(\"Starting Visual Inspection for ALL data...\")\n",
        "\n",
        "for split in splits_to_check:\n",
        "    print(f\"\\n--- Processing {split.upper()} set ---\")\n",
        "\n",
        "    # Define input paths\n",
        "    img_dir = os.path.join(base_dataset_dir, split, 'images')\n",
        "    lbl_dir = os.path.join(base_dataset_dir, split, 'labels')\n",
        "\n",
        "    # Define output path (e.g., check_training_labels, check_val_labels)\n",
        "    output_dir = os.path.join(base_dataset_dir, f'check_{split}_labels_visual')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get all images\n",
        "    if not os.path.exists(img_dir):\n",
        "        print(f\"Skipping {split} (folder not found)\")\n",
        "        continue\n",
        "\n",
        "    image_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    print(f\"Saving images to: {output_dir}\")\n",
        "\n",
        "    # Loop with progress bar\n",
        "    for img_file in tqdm(image_files):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "\n",
        "        # Find matching label\n",
        "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
        "        label_path = os.path.join(lbl_dir, label_file)\n",
        "\n",
        "        # Read Image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None: continue\n",
        "        h_img, w_img = img.shape[:2]\n",
        "\n",
        "        # Draw Boxes if label exists\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            valid_label = False\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 5: continue\n",
        "\n",
        "                try:\n",
        "                    cls_id = int(parts[0])\n",
        "                    x_center, y_center, w, h = map(float, parts[1:])\n",
        "\n",
        "                    # Convert YOLO normalized -> Pixels\n",
        "                    x1 = int((x_center - w/2) * w_img)\n",
        "                    y1 = int((y_center - h/2) * h_img)\n",
        "                    x2 = int((x_center + w/2) * w_img)\n",
        "                    y2 = int((y_center + h/2) * h_img)\n",
        "\n",
        "                    # Draw Rectangle\n",
        "                    color = COLOR_MAP.get(cls_id, (255, 255, 255))\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, BOX_THICKNESS)\n",
        "\n",
        "                    # Draw ID\n",
        "                    label_text = \"V\" if cls_id == 0 else \"NV\"\n",
        "                    cv2.putText(img, label_text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "                    valid_label = True\n",
        "                except ValueError:\n",
        "                    continue # Skip corrupt lines\n",
        "\n",
        "            # If label file was empty\n",
        "            if not valid_label and os.path.getsize(label_path) == 0:\n",
        "                 cv2.putText(img, \"EMPTY LABEL FILE\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "\n",
        "        else:\n",
        "            # Mark MISSING labels clearly\n",
        "            cv2.putText(img, \"NO LABEL FOUND\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "            # Optional: Draw a red border around the whole image to verify it's a negative sample\n",
        "            cv2.rectangle(img, (0,0), (w_img, h_img), (0,0,255), 10)\n",
        "\n",
        "        # Save the annotated image\n",
        "        cv2.imwrite(os.path.join(output_dir, img_file), img)\n",
        "\n",
        "print(\"\\nDone! Please check these folders in your Drive:\")\n",
        "print(f\"1. {os.path.join(base_dataset_dir, 'check_train_labels_visual')}\")\n",
        "print(f\"2. {os.path.join(base_dataset_dir, 'check_val_labels_visual')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ormC0rauay-n"
      },
      "source": [
        "### ‚öôÔ∏è Step 5: Configure Model Hyperparameters\n",
        "This cell generates the `data.yaml` file required by YOLO. It defines the paths to your Train/Val folders and the class names.\n",
        "\n",
        "* **Classes:** `['viable', 'non_viable']`\n",
        "* **Path:** Points to your Google Drive dataset location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwSn12MSF1LY",
        "outputId": "06830ada-8edf-4cd2-fc8d-da3570f50bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration file created at: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/data.yaml\n",
            "--- Content ---\n",
            "names:\n",
            "- viable\n",
            "- non_viable\n",
            "nc: 2\n",
            "path: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1\n",
            "train: train/images\n",
            "val: val/images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# Define the content of the data.yaml file\n",
        "data_config = {\n",
        "    # PATHS: Points to where we just moved your files\n",
        "    'path': '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1',\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "\n",
        "    # CLASSES:\n",
        "    # IMPORTANT: These must match your annotation IDs (0, 1, etc.)\n",
        "    # Example: If your .txt file says \"0 0.5 0.5...\", \"0\" corresponds to the first name here.\n",
        "    'nc': 2,  # Number of classes\n",
        "    'names': ['viable', 'non_viable'] # Change these names to match your data!\n",
        "}\n",
        "\n",
        "# Save it to the dataset folder\n",
        "yaml_path = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/data.yaml'\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"Configuration file created at: {yaml_path}\")\n",
        "print(\"--- Content ---\")\n",
        "print(open(yaml_path).read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjwAV8YJWac"
      },
      "source": [
        "### üèãÔ∏è‚Äç‚ôÄÔ∏è Step 6: Train the Model\n",
        "This process will take 1-3 hours depending on the model size.\n",
        "\n",
        "**Biological Hyperparameters:**\n",
        "We use specific augmentations to make the model robust to microscope variations:\n",
        "* `degrees=180`: Pollen has no \"up\" or \"down\" (rotational invariance).\n",
        "* `flipud=0.5`: Vertical flipping enabled.\n",
        "* `hsv_s=0.1`: **Low Saturation Noise**. We limit color augmentation because color (Dark vs. Pale) is the primary viability signal.\n",
        "* `patience=50`: Early Stopping is enabled. If the model stops improving for 50 epochs, training stops to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3wVXGWCYmkd",
        "outputId": "567ec99f-ac4d-4b68-c603-4eec3464f04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/data.yaml, degrees=180, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.005, hsv_s=0.1, hsv_v=0.6, imgsz=640, int8=False, iou=0.45, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0, mode=train, model=/content/runs/detect/pollen_v1_aug3/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pollen_v1_aug6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/pollen_v1_aug6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5584342  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
            "Model summary: 209 layers, 43,631,382 parameters, 43,631,366 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 10.1¬±21.6 ms, read: 42.8¬±84.6 MB/s, size: 164.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/labels.cache... 252 images, 40 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 252/252 445.6Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train/images/2-13-J_S4x_C_train10_png.rf.d324de31e7e6f03ff4a4cd5e4a345c13.jpg: 1 duplicate labels removed\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 539, len(boxes) = 2223. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.6¬±0.1 ms, read: 87.9¬±28.3 MB/s, size: 317.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/val/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 54/54 54.1Kit/s 0.0s\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 153, len(boxes) = 610. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/pollen_v1_aug6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/pollen_v1_aug6\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/300      21.1G     0.7093     0.4255     0.9871        285        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.4s/it 11.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.954      0.954      0.952      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/300      18.9G     0.6858     0.4088     0.9766        181        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0s/it 8.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2it/s 0.8s\n",
            "                   all         54        610      0.949      0.961      0.952      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/300      18.8G     0.6455     0.3761     0.9589        218        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0s/it 8.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.955      0.956      0.961      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/300      18.8G     0.6584     0.3698     0.9652        235        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0s/it 8.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.952      0.964      0.961      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/300      18.9G     0.6376     0.3708     0.9544        272        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0s/it 8.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.963      0.945      0.954      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/300      18.9G     0.6537     0.3786     0.9553        334        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0s/it 8.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.948      0.925       0.95      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/300      18.9G     0.6719     0.3799     0.9577        260        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.959      0.935      0.955      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/300      18.9G      0.681     0.3876       0.97        331        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610       0.96      0.944      0.957      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/300      18.9G      0.641      0.377      0.957        302        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.958      0.942      0.959      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/300      18.9G     0.6765      0.399     0.9772        252        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.954      0.947      0.959      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/300      18.9G      0.657      0.385     0.9634        294        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.949      0.938      0.953      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/300      18.9G     0.6553      0.388     0.9635        272        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610       0.94      0.953      0.961      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/300      18.6G     0.6843     0.3954     0.9793        310        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.963      0.962      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/300      18.9G     0.6777     0.3844     0.9717        277        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.935      0.934      0.933      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/300      18.6G     0.7095     0.4045     0.9864        293        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.937      0.953      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/300      18.9G     0.7164     0.4131     0.9881        310        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.943      0.921      0.953      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/300      18.9G     0.7329     0.4132     0.9901        273        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.931      0.956       0.96      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/300      18.9G     0.6976     0.4012     0.9799        312        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.942      0.963       0.96      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/300      18.9G     0.7042     0.3993     0.9768        273        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.948      0.961       0.96      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/300      18.9G     0.6759     0.3746      0.974        290        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.948      0.929      0.955      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/300      18.8G     0.7088     0.4004     0.9801        321        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.918      0.934      0.947       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/300      18.9G     0.6452     0.3724      0.954        261        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.934      0.894      0.949      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/300      18.9G     0.6632       0.39     0.9664        341        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.961      0.914      0.943      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/300      18.9G     0.6467     0.3917     0.9689        267        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.959       0.92      0.937      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/300      18.9G       0.68     0.3868     0.9639        330        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.939       0.94      0.948      0.751\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/300      18.9G     0.6559     0.3853     0.9593        295        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.933      0.961      0.959      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/300      18.9G      0.657     0.3809     0.9622        251        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.944      0.952      0.954      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/300      18.9G     0.6851     0.3909     0.9803        350        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.946      0.949      0.949      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/300      18.9G      0.648     0.3721     0.9531        352        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.953      0.941      0.947      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/300      18.9G      0.691      0.381      0.969        332        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.944      0.939      0.939      0.771\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/300      18.8G     0.6898     0.3887     0.9723        263        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.937      0.961      0.958       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/300      18.9G     0.6626      0.371     0.9581        233        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.948       0.96      0.966      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/300      18.8G     0.7224     0.4038     0.9865        210        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.937       0.95      0.962      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/300      18.9G     0.6839     0.3961     0.9771        246        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.938      0.951      0.954      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/300      18.8G     0.6634     0.3811     0.9695        271        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.935      0.959      0.951      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/300      18.9G     0.6434     0.3876     0.9598        280        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.931      0.951      0.951        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/300      18.8G     0.6448     0.3727     0.9665        377        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.957       0.92      0.958      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/300      18.8G      0.637     0.3505      0.952        253        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.907      0.925      0.955       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/300      18.8G     0.6371     0.3702     0.9467        310        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.962      0.922      0.952      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/300      18.9G     0.6364     0.3701     0.9509        265        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.953      0.937      0.961      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/300      18.9G     0.6293     0.3712     0.9476        322        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.961      0.964      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/300      18.9G     0.6554     0.3804     0.9694        292        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610       0.93      0.955      0.962      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/300      18.8G     0.6604     0.3789     0.9601        278        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.932      0.967      0.966        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/300      18.8G     0.6741     0.3928     0.9623        233        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.937      0.967      0.965      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/300      18.6G     0.6788     0.3788     0.9687        302        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.936      0.947       0.96      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/300      18.7G     0.6828     0.3929     0.9754        285        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.931      0.973       0.96      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/300      18.9G     0.6957     0.4001     0.9829        212        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.942      0.967      0.965      0.754\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/300      18.8G     0.6364     0.3594     0.9574        337        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.934      0.965      0.964      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/300      18.8G     0.6865     0.3884     0.9855        239        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.952      0.935      0.951      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/300      18.9G     0.6381     0.3651     0.9578        276        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.936      0.938      0.947      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/300      18.8G     0.6313     0.3635     0.9474        283        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.942      0.917      0.953      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/300      18.9G     0.6334     0.3557     0.9569        284        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.916      0.963      0.952       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/300      18.8G     0.6451     0.3785     0.9641        243        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.942      0.973      0.961      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/300      18.9G     0.6154      0.349     0.9385        346        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.956      0.949      0.969      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/300      18.8G     0.6362     0.3639     0.9589        258        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.931      0.963      0.961      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/300      18.8G     0.6135     0.3499      0.944        320        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.958      0.935      0.954      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/300      18.9G     0.6172     0.3569     0.9431        274        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.958      0.937      0.959      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/300      18.9G     0.6211     0.3506     0.9512        284        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.962      0.945      0.965      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/300      18.8G     0.6158     0.3494     0.9456        300        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.935      0.964       0.96      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/300      18.8G     0.6293     0.3629     0.9564        330        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.927      0.953      0.958      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/300      18.9G     0.6353     0.3602     0.9516        295        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.934      0.932      0.953      0.761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/300      18.9G     0.6699     0.3718     0.9704        259        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.944       0.95       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/300      18.9G     0.6472     0.3536     0.9488        385        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.946      0.958      0.954      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/300      18.9G      0.618     0.3452     0.9475        273        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.946      0.951      0.954       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/300      18.9G     0.6067     0.3534     0.9417        281        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.942      0.946      0.955      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/300      18.9G      0.636     0.3544      0.948        288        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.937      0.953      0.954      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/300      18.8G     0.6218     0.3501       0.95        260        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.935      0.967      0.954      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/300      18.8G     0.6305     0.3542     0.9518        240        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.956      0.947      0.942      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/300      18.9G     0.6505     0.3415     0.9543        295        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.949      0.959      0.958      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/300      18.5G     0.6348     0.3378     0.9517        389        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.963      0.955        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/300      18.8G     0.6241     0.3614     0.9507        268        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610       0.96      0.938      0.953      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/300      18.8G     0.6257      0.354     0.9519        298        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.944      0.941      0.944      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/300      18.9G     0.6158     0.3528     0.9439        337        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.951      0.954      0.956      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/300      18.8G     0.6359      0.372     0.9569        224        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.818      0.862      0.881      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/300      18.8G     0.6207     0.3659     0.9488        340        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.932      0.957      0.953      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/300      18.9G     0.6157     0.3554     0.9495        323        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.941      0.945      0.953      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/300      18.9G     0.6321     0.3649     0.9513        303        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.951      0.946      0.957      0.812\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/300      18.8G     0.6186     0.3427     0.9377        332        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.936      0.964      0.958      0.757\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/300      18.8G     0.6137     0.3501     0.9424        301        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.937      0.973      0.963      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/300      18.8G     0.6512     0.3512     0.9568        283        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3it/s 0.8s\n",
            "                   all         54        610      0.943      0.959       0.95      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/300      18.9G     0.6226     0.3468     0.9448        363        640: 50% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/8 1.3s/it 5.0s<5.3s"
          ]
        }
      ],
      "source": [
        "#Train the model\n",
        "# data: Points to the yaml file we just created\n",
        "# epochs: How many times to cycle through the data (start low to test)\n",
        "# imgsz: Image size (640 is standard for YOLO)\n",
        "# We pass these arguments directly to the train() function.\n",
        "results = model.train(\n",
        "    data='/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/data.yaml',\n",
        "    epochs=300,\n",
        "    patience=50,       # Stop if no improvement for 50 epochs\n",
        "    imgsz=640,\n",
        "    batch=32, # Reduced batch size to conserve memory\n",
        "    name='pollen_v1_aug', # New name so we don't overwrite the old one\n",
        "\n",
        "    # --- AUGMENTATION PARAMETERS ---\n",
        "    degrees=180,        # Rotate image randomly between -180 and +180 (Pollen has no \"up\")\n",
        "    flipud=0.5,         # 50% chance to flip Up-Down (Pollen doesn't care about gravity)\n",
        "    fliplr=0.5,         # 50% chance to flip Left-Right\n",
        "    scale=0.1,\n",
        "       # Zoom in/out by up to 10% (Simulates different crop sizes) - lets play with it, lets try to put it down\n",
        "    hsv_h=0.005,        # Adjust Hue slightly (Color variation)\n",
        "    hsv_s=0.1,          # Adjust Saturation (Some images might be paler)\n",
        "    hsv_v=0.6,          # Adjust Value/Brightness (Microscope lighting changes)\n",
        "    iou=0.45,           #\n",
        "\n",
        "    # Advanced Mixes\n",
        "    mosaic=1.0,         # (Default) Stitches 4 images together. Great for small objects.\n",
        "    mixup=0,          # Blends 2 images together. Helps with overlapping pollen.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_JumiBTKVtt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gxthIymDvWE"
      },
      "source": [
        "### üíæ Step 7: Save the \"Golden\" Model\n",
        "The training results are temporarily stored in Colab's memory (`/content/runs/...`). This script copies the **best** performing weights to your Google Drive for permanent storage.\n",
        "\n",
        "* **Destination:** `Pollen_viability/trained_models/`\n",
        "* **Naming:** Includes the date (e.g., `pollen_model_2025-12-10.pt`) so you can track versions.\n",
        "\n",
        "**Code (GitHub):**\n",
        "The repository contains the *pipeline* (notebooks, scripts, config).\n",
        "* `pollen_viability.ipynb`: Main training/inference workflow.\n",
        "* `datasets/data.yaml`: Configuration map.\n",
        "\n",
        "**Artifacts (Google Drive):**\n",
        "Due to file size constraints, trained model weights (`.pt` files) are stored in Google Drive, not GitHub.\n",
        "* Location: `Pollen_viability/trained_models/`\n",
        "* Naming Convention: `pollen_yolo_aug_YYYY-MM-DD.pt`\n",
        "\n",
        "**Reproducibility:**\n",
        "To reproduce results, clone the GitHub repo, mount Drive, and point the `model = YOLO()` function to the specific `.pt` file in Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kGIec_aJIX8"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. Define where your weights are NOW (Temporary Colab storage)\n",
        "# Note: Check the folder name 'pollen_v1_aug' matches your training \"name=\" parameter\n",
        "source_weight = '/content/runs/detect/pollen_v1_aug6/weights/best.pt'\n",
        "\n",
        "# 2. Define where you want them PERMANENTLY (Google Drive)\n",
        "# We add a timestamp so you never overwrite good models\n",
        "date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "dest_folder = '/content/drive/MyDrive/Pollen_viability/trained_models'\n",
        "dest_filename = f'pollen_yolo_aug_{date_str}.pt'\n",
        "dest_path = os.path.join(dest_folder, dest_filename)\n",
        "\n",
        "# 3. Copy the file\n",
        "if os.path.exists(source_weight):\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "    shutil.copy(source_weight, dest_path)\n",
        "    print(f\"‚úÖ Model saved safely to: {dest_path}\")\n",
        "    print(\"You can now download this file or load it from Drive anytime.\")\n",
        "else:\n",
        "    print(f\"‚ùå Could not find {source_weight}. Did the training finish?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhUfCDSjiJr-"
      },
      "source": [
        "### üî¨ Step 8: Routine Detection Tool\n",
        "**Use this section to process new experiments.**\n",
        "\n",
        "1.  **Input:** Upload your raw microscope images to `detect_images/`.\n",
        "2.  **Run:** Execute the cell below.\n",
        "3.  **Output:**\n",
        "    * **CSV:** `pollen_counts.csv` (Contains Viable/Non-Viable counts for every image).\n",
        "    * **Visuals:** Annotated images saved in `detected/`.\n",
        "\n",
        "**Dynamic Resolution Logic:**\n",
        "The script automatically detects if an image is a **Full Slide Scan** (>1000px) or a **Crop**.\n",
        "* **Full Slide:** Uses High-Res inference (`imgsz=1600`) to find small grains.\n",
        "* **Crop:** Uses Standard inference (`imgsz=640`) to avoid scaling artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTjLLuXsLTZp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "model_path = '/content/runs/detect/pollen_v1_aug6/weights/best.pt'\n",
        "image_dir = '/content/drive/MyDrive/Pollen_viability/detect_images'\n",
        "save_image_dir = '/content/drive/MyDrive/Pollen_viability/detected'\n",
        "output_csv_path = '/content/drive/MyDrive/Pollen_viability/pollen_counts_universal.csv'\n",
        "\n",
        "# --- THRESHOLDS (Set them here!) ---\n",
        "CONF_VIABLE = 0.60\n",
        "CONF_NON_VIABLE = 0.45\n",
        "\n",
        "# Visualization Config\n",
        "COLOR_VIABLE = (0, 200, 0)      # Green\n",
        "COLOR_NON_VIABLE = (0, 0, 200)  # Red\n",
        "BOX_THICKNESS = 4               # Thinned slightly for clarity\n",
        "\n",
        "os.makedirs(save_image_dir, exist_ok=True)\n",
        "model = YOLO(model_path)\n",
        "\n",
        "print(f\"--- STARTING DEBUG RUN ---\")\n",
        "print(f\"Viable Threshold: {CONF_VIABLE}\")\n",
        "print(f\"Non-Viable Threshold: {CONF_NON_VIABLE}\")\n",
        "\n",
        "data_rows = []\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "for img_file in image_files:\n",
        "    img_path = os.path.join(image_dir, img_file)\n",
        "\n",
        "    # 1. READ IMAGE\n",
        "    img_array = cv2.imread(img_path)\n",
        "    height, width = img_array.shape[:2]\n",
        "\n",
        "    # 2. DYNAMIC LOGIC\n",
        "    if width > 1000 or height > 1000:\n",
        "        inference_size = 1600\n",
        "        mode = \"High-Res\"\n",
        "    else:\n",
        "        inference_size = 640\n",
        "        mode = \"Standard\"\n",
        "\n",
        "    # 3. RUN INFERENCE (Low conf to catch everything, filter later)\n",
        "    results = model(img_path, verbose=False, imgsz=inference_size, conf=0.1)\n",
        "\n",
        "    boxes = results[0].boxes\n",
        "    keep_indices = []\n",
        "\n",
        "    final_counts = {'viable': 0, 'non_viable': 0}\n",
        "\n",
        "    if boxes:\n",
        "        # Convert to numpy for easy looping\n",
        "        cls_ids = boxes.cls.cpu().numpy().astype(int)\n",
        "        confs = boxes.conf.cpu().numpy()\n",
        "\n",
        "        for i, (cls_id, conf) in enumerate(zip(cls_ids, confs)):\n",
        "            conf = float(conf) # Ensure it's a standard python float\n",
        "\n",
        "            # --- DEBUG LOGIC ---\n",
        "            is_kept = False\n",
        "\n",
        "            if cls_id == 0: # Viable\n",
        "                if conf > CONF_VIABLE:\n",
        "                    final_counts['viable'] += 1\n",
        "                    keep_indices.append(i)\n",
        "                    is_kept = True\n",
        "                else:\n",
        "                    # Print when we REJECT something that is close\n",
        "                    if conf > 0.5:\n",
        "                        print(f\"[{img_file}] REJECTED Viable with score {conf:.2f} (Threshold {CONF_VIABLE})\")\n",
        "\n",
        "            elif cls_id == 1: # Non-Viable\n",
        "                if conf > CONF_NON_VIABLE:\n",
        "                    final_counts['non_viable'] += 1\n",
        "                    keep_indices.append(i)\n",
        "                    is_kept = True\n",
        "                else:\n",
        "                    if conf > 0.2:\n",
        "                        print(f\"[{img_file}] REJECTED Non-Viable with score {conf:.2f} (Threshold {CONF_NON_VIABLE})\")\n",
        "\n",
        "    # 4. DRAWING LOOP\n",
        "    for idx in keep_indices:\n",
        "        x1, y1, x2, y2 = boxes.xyxy[idx].cpu().numpy().astype(int)\n",
        "        cls_id = int(boxes.cls[idx])\n",
        "        conf = float(boxes.conf[idx])\n",
        "\n",
        "        color = COLOR_VIABLE if cls_id == 0 else COLOR_NON_VIABLE\n",
        "        label = \"V\" if cls_id == 0 else \"NV\"\n",
        "\n",
        "        cv2.rectangle(img_array, (x1, y1), (x2, y2), color, BOX_THICKNESS)\n",
        "\n",
        "        label_text = f\"{label} {conf:.2f}\"\n",
        "        (w, h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(img_array, (x1, y1 - 20), (x1 + w, y1), color, -1)\n",
        "        cv2.putText(img_array, label_text, (x1, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "    # Save\n",
        "    save_path = os.path.join(save_image_dir, img_file)\n",
        "    cv2.imwrite(save_path, img_array)\n",
        "\n",
        "    # Log Data\n",
        "    row = {\n",
        "        'image_id': img_file,\n",
        "        'viable_pollen': final_counts['viable'],\n",
        "        'non_viable_pollen': final_counts['non_viable'],\n",
        "        'Total Objects': final_counts['viable'] + final_counts['non_viable'],\n",
        "        'resolution_mode': inference_size\n",
        "    }\n",
        "    data_rows.append(row)\n",
        "\n",
        "# Save CSV\n",
        "df_results = pd.DataFrame(data_rows).sort_values(by='image_id')\n",
        "df_results.to_csv(output_csv_path, index=False)\n",
        "print(\"\\nProcessing Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUxKy236-BiA"
      },
      "source": [
        "## Dataset updates  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXBqDN1q-D5v",
        "outputId": "e39923fa-6574-4703-ab9a-42c81229fc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Smart Split & Merge (Train + Val)...\n",
            "1Ô∏è‚É£ Found zip file: Viable_pollen.v7i.yolov8.zip\n",
            "   Unzipping to temp workspace...\n",
            "   Scanning extracted files...\n",
            "   Found 89 valid Image+Label pairs in zip.\n",
            "\n",
            "2Ô∏è‚É£ Checking for Duplicates...\n",
            "   ‚ö†Ô∏è Skipped 7 images that already exist in Train or Val.\n",
            "\n",
            "3Ô∏è‚É£ Splitting and Merging...\n",
            "   (Backup saved to backups/dataset_backup_20251210_2048.zip)\n",
            "   Adding 70 to TRAIN.\n",
            "   Adding 12 to VAL.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Moving to train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:01<00:00, 68.91it/s]\n",
            "Moving to val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 73.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ SUCCESS! Dataset updated safely.\n",
            "   Total added: 82\n",
            "   You can delete the zip file from staged_area now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import datetime\n",
        "import glob\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# 1. Search for Zip\n",
        "search_root = '/content/drive/MyDrive/Pollen_viability/staged_area'\n",
        "\n",
        "# 2. Main Dataset Folders (Now we track BOTH)\n",
        "dataset_root = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1'\n",
        "train_dir = os.path.join(dataset_root, 'train')\n",
        "val_dir = os.path.join(dataset_root, 'val')\n",
        "\n",
        "# 3. Settings\n",
        "VAL_SPLIT_RATIO = 0.15  # 15% goes to Validation\n",
        "temp_dir = '/content/temp_roboflow_process'\n",
        "\n",
        "print(\"üöÄ Starting Smart Split & Merge (Train + Val)...\")\n",
        "\n",
        "# --- A. FIND THE ZIP FILE ---\n",
        "possible_zips = glob.glob(os.path.join(search_root, \"*.zip\")) + \\\n",
        "                glob.glob(os.path.join(search_root, \"labels\", \"*.zip\"))\n",
        "\n",
        "if not possible_zips:\n",
        "    print(f\"‚ùå Error: No .zip files found in {search_root}\")\n",
        "    raise FileNotFoundError(\"Stopping. Please check uploaded zip location.\")\n",
        "\n",
        "roboflow_zip = possible_zips[0]\n",
        "print(f\"1Ô∏è‚É£ Found tzip file: {os.path.basename(roboflow_zip)}\")\n",
        "\n",
        "# --- B. CLEANUP & UNZIP ---\n",
        "if os.path.exists(temp_dir): shutil.rmtree(temp_dir)\n",
        "os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "print(f\"   Unzipping to temp workspace...\")\n",
        "with zipfile.ZipFile(roboflow_zip, 'r') as z:\n",
        "    z.extractall(temp_dir)\n",
        "\n",
        "# --- C. HUNT DOWN NEW DATA ---\n",
        "found_pairs = [] # We store (image_path, label_path) tuples\n",
        "\n",
        "print(\"   Scanning extracted files...\")\n",
        "# Helper to find matching label for an image\n",
        "def find_label(img_path, search_dir):\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    # Look for .txt with same base name in the whole temp tree\n",
        "    for r, d, f in os.walk(search_dir):\n",
        "        for file in f:\n",
        "            if file == base_name + \".txt\":\n",
        "                return os.path.join(r, file)\n",
        "    return None\n",
        "\n",
        "for root, dirs, files in os.walk(temp_dir):\n",
        "    for f in files:\n",
        "        if f.startswith('._'): continue\n",
        "        if f.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "            img_full_path = os.path.join(root, f)\n",
        "            lbl_full_path = find_label(img_full_path, temp_dir)\n",
        "\n",
        "            if lbl_full_path:\n",
        "                found_pairs.append((img_full_path, lbl_full_path))\n",
        "\n",
        "print(f\"   Found {len(found_pairs)} valid Image+Label pairs in zip.\")\n",
        "\n",
        "# --- D. DUPLICATE CHECK ---\n",
        "print(\"\\n2Ô∏è‚É£ Checking for Duplicates...\")\n",
        "# Get list of ALL current files to avoid collisions\n",
        "existing_files = set()\n",
        "for split in [train_dir, val_dir]:\n",
        "    img_dir = os.path.join(split, 'images')\n",
        "    if os.path.exists(img_dir):\n",
        "        existing_files.update(os.listdir(img_dir))\n",
        "\n",
        "unique_pairs = []\n",
        "skipped_count = 0\n",
        "\n",
        "for img_path, lbl_path in found_pairs:\n",
        "    fname = os.path.basename(img_path)\n",
        "    if fname in existing_files:\n",
        "        skipped_count += 1\n",
        "        # Optional: Print duplicate names\n",
        "        # print(f\"   Skipping duplicate: {fname}\")\n",
        "    else:\n",
        "        unique_pairs.append((img_path, lbl_path))\n",
        "\n",
        "if skipped_count > 0:\n",
        "    print(f\"   ‚ö†Ô∏è Skipped {skipped_count} images that already exist in Train or Val.\")\n",
        "else:\n",
        "    print(\"   ‚úÖ No duplicates found.\")\n",
        "\n",
        "if len(unique_pairs) == 0:\n",
        "    raise RuntimeError(\"No new unique images to add! Stopping.\")\n",
        "\n",
        "# --- E. SPLIT & MERGE ---\n",
        "print(\"\\n3Ô∏è‚É£ Splitting and Merging...\")\n",
        "\n",
        "# Backup (Backs up the whole pollen_v1 folder structure)\n",
        "backup_name = f\"dataset_backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "backup_path = f\"/content/drive/MyDrive/Pollen_viability/backups/{backup_name}\"\n",
        "shutil.make_archive(backup_path, 'zip', dataset_root)\n",
        "print(f\"   (Backup saved to backups/{backup_name}.zip)\")\n",
        "\n",
        "# Randomize\n",
        "random.shuffle(unique_pairs)\n",
        "\n",
        "# Calculate Split Index\n",
        "split_idx = int(len(unique_pairs) * VAL_SPLIT_RATIO)\n",
        "val_batch = unique_pairs[:split_idx]\n",
        "train_batch = unique_pairs[split_idx:]\n",
        "\n",
        "print(f\"   Adding {len(train_batch)} to TRAIN.\")\n",
        "print(f\"   Adding {len(val_batch)} to VAL.\")\n",
        "\n",
        "def move_batch(batch, destination_dir):\n",
        "    img_dest = os.path.join(destination_dir, 'images')\n",
        "    lbl_dest = os.path.join(destination_dir, 'labels')\n",
        "    os.makedirs(img_dest, exist_ok=True)\n",
        "    os.makedirs(lbl_dest, exist_ok=True)\n",
        "\n",
        "    for img, lbl in tqdm(batch, desc=f\"Moving to {os.path.basename(destination_dir)}\"):\n",
        "        shutil.copy2(img, os.path.join(img_dest, os.path.basename(img)))\n",
        "        shutil.copy2(lbl, os.path.join(lbl_dest, os.path.basename(lbl)))\n",
        "\n",
        "# Execute Move\n",
        "move_batch(train_batch, train_dir)\n",
        "move_batch(val_batch, val_dir)\n",
        "\n",
        "print(\"\\n‚úÖ SUCCESS! Dataset updated safely.\")\n",
        "print(f\"   Total added: {len(unique_pairs)}\")\n",
        "print(\"   You can delete the zip file from staged_area now.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dealing with the smudges"
      ],
      "metadata": {
        "id": "e68Pmzs8PL9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# 1. Input: Folder where you put your small smudge crops\n",
        "input_smudges_dir = '/content/drive/MyDrive/Pollen_viability/smudges_raw'\n",
        "\n",
        "# 2. Output: Where the training-ready files go\n",
        "output_dir = '/content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train_negatives'\n",
        "os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "# 3. Settings\n",
        "CANVAS_SIZE = 640\n",
        "# Approx color of your slide background (Light Gray/White)\n",
        "# BGR format: (240, 240, 240) is nearly white\n",
        "BACKGROUND_COLOR = (245, 245, 245)\n",
        "\n",
        "print(\"üß™ Starting Smudge Synthesis...\")\n",
        "\n",
        "if not os.path.exists(input_smudges_dir) or not os.listdir(input_smudges_dir):\n",
        "    print(f\"‚ùå Error: Folder '{input_smudges_dir}' is empty or missing.\")\n",
        "    print(\"   Please upload your small smudge crops there first.\")\n",
        "else:\n",
        "    files = [f for f in os.listdir(input_smudges_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    print(f\"   Found {len(files)} smudge samples.\")\n",
        "\n",
        "    for i, fname in enumerate(tqdm(files)):\n",
        "        # Load Smudge\n",
        "        smudge = cv2.imread(os.path.join(input_smudges_dir, fname))\n",
        "        if smudge is None: continue\n",
        "\n",
        "        h, w = smudge.shape[:2]\n",
        "\n",
        "        # Create Canvas\n",
        "        canvas = np.full((CANVAS_SIZE, CANVAS_SIZE, 3), BACKGROUND_COLOR, dtype=np.uint8)\n",
        "\n",
        "        # Calculate Center Position\n",
        "        # If smudge is bigger than canvas, resize it down\n",
        "        if w > CANVAS_SIZE or h > CANVAS_SIZE:\n",
        "            scale = min(CANVAS_SIZE/w, CANVAS_SIZE/h)\n",
        "            smudge = cv2.resize(smudge, (0,0), fx=scale, fy=scale)\n",
        "            h, w = smudge.shape[:2]\n",
        "\n",
        "        x_offset = (CANVAS_SIZE - w) // 2\n",
        "        y_offset = (CANVAS_SIZE - h) // 2\n",
        "\n",
        "        # Paste Smudge onto Canvas\n",
        "        canvas[y_offset:y_offset+h, x_offset:x_offset+w] = smudge\n",
        "\n",
        "        # Save Final Image\n",
        "        new_name = f\"negative_smudge_{i}.jpg\"\n",
        "        cv2.imwrite(os.path.join(output_dir, 'images', new_name), canvas)\n",
        "\n",
        "        # Save EMPTY Label\n",
        "        with open(os.path.join(output_dir, 'labels', new_name.replace('.jpg', '.txt')), 'w') as f:\n",
        "            pass # Empty file = \"Nothing to see here\"\n",
        "\n",
        "    print(f\"\\n‚úÖ Created {len(files)} negative training samples.\")\n",
        "    print(f\"üìÇ Saved to: {output_dir}\")\n",
        "    print(\"üëâ Next Step: Move these folders into your main 'train' folder and retrain!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-boHRNRJq0d",
        "outputId": "6edc96c8-73ca-4dc1-98fb-882d2ede5c08"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Starting Smudge Synthesis...\n",
            "   Found 40 smudge samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:36<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Created 40 negative training samples.\n",
            "üìÇ Saved to: /content/drive/MyDrive/Pollen_viability/datasets/pollen_v1/train_negatives\n",
            "üëâ Next Step: Move these folders into your main 'train' folder and retrain!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "mount_file_id": "1fo5vSY2gq35_XyJZwm0M4DC9EyFXCXvo",
      "authorship_tag": "ABX9TyPuan0+H7vYb5GgigJMCwV3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}